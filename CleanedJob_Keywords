import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

# Load the CSV file
file_path = "Cleaned_DS_Jobs.csv"  # Replace with the actual file path
df = pd.read_csv(file_path)

# Select the "Job Description" column and remove missing values
job_descriptions = df["Job Description"].dropna().head(500)  # Process only the first 500 rows for efficiency

# Initialize the TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words="english", max_features=20)  # Limit to extracting 20 keywords

# Train the TF-IDF model and transform the text data
tfidf_matrix = tfidf_vectorizer.fit_transform(job_descriptions)

# Get the extracted keywords
feature_names = tfidf_vectorizer.get_feature_names_out()

# Compute the importance score for each word (take the mean TF-IDF score)
mean_tfidf_scores = np.asarray(tfidf_matrix.mean(axis=0)).flatten()

# Sort keywords by importance score in descending order
keywords = sorted(zip(feature_names, mean_tfidf_scores), key=lambda x: x[1], reverse=True)

# Display the top 10 highest-ranked keywords
for word, score in keywords[:10]:
    print(f"{word}: {score:.4f}")
