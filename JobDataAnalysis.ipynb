{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码格式转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录：/Users/os/Desktop/mdm2222\n",
      "文件已转换为UTF-8编码并保存为：/Users/os/Desktop/mdm2222/Cleaned_DS_Jobs_utf8_utf8.csv\n",
      "文件已转换为UTF-8编码并保存为：/Users/os/Desktop/mdm2222/Cleaned_DS_Jobs_utf8_utf8_utf8.csv\n",
      "文件已转换为UTF-8编码并保存为：/Users/os/Desktop/mdm2222/DataAnalyst_utf8_utf8.csv\n",
      "文件已转换为UTF-8编码并保存为：/Users/os/Desktop/mdm2222/DataAnalyst_utf8_utf8_utf8.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "def get_encoding(filename):\n",
    "    \"\"\"\n",
    "    检测并返回文件的编码格式。\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        return result['encoding']\n",
    "\n",
    "def convert_to_utf8(filename):\n",
    "    \"\"\"\n",
    "    将文件转换为UTF-8编码格式。\n",
    "    \"\"\"\n",
    "    encoding = get_encoding(filename)  # 获取文件的原始编码\n",
    "    try:\n",
    "        # 尝试使用检测到的编码读取文件\n",
    "        df = pd.read_csv(filename, encoding=encoding)\n",
    "    except UnicodeDecodeError:\n",
    "        # 如果检测到的编码失败，尝试使用常见的编码\n",
    "        try:\n",
    "            df = pd.read_csv(filename, encoding='gbk')  # 尝试使用GBK编码\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(filename, encoding='gb18030')  # 尝试使用GB18030编码\n",
    "\n",
    "    # 生成新的文件名\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    new_filename = f\"{base}_utf8{ext}\"\n",
    "\n",
    "    # 保存为UTF-8编码的新文件\n",
    "    df.to_csv(new_filename, encoding='utf-8', index=False)\n",
    "    print(f\"文件已转换为UTF-8编码并保存为：{new_filename}\")\n",
    "\n",
    "def batch_convert_to_utf8(path, ext_name='csv'):\n",
    "    \"\"\"\n",
    "    批量转换指定目录下所有指定后缀的文件为UTF-8编码。\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.' + ext_name):\n",
    "            full_path = os.path.join(path, filename)\n",
    "            convert_to_utf8(full_path)\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 使用当前工作目录\n",
    "    path = os.getcwd()  # 获取当前工作目录\n",
    "    print(f\"当前工作目录：{path}\")\n",
    "    batch_convert_to_utf8(path)  # 调用批量转换函数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# # 设置 Pandas 显示所有列\n",
    "# pd.set_option('display.max_columns', None)  # 设置为 None，表示显示所有列\n",
    "# pd.set_option('display.max_colwidth', None)  # 设置为 None，表示显示完整的列宽\n",
    "# pd.set_option('display.width', None)  # 设置为 None，表示显示完整的宽度\n",
    "\n",
    "\n",
    "# 1. 文件读取\n",
    "\n",
    "# 读取两个CSV文件\n",
    "df_ds = pd.read_csv('Cleaned_DS_Jobs_utf8.csv')\n",
    "df_da = pd.read_csv('DataAnalyst_utf8.csv')\n",
    "\n",
    "# 计算公司成立年份\n",
    "df_ds['Founded'] = 2020 - df_ds['company_age']\n",
    "df_ds.drop(columns=['company_age'], inplace=True)\n",
    "\n",
    "# 处理公司名称中的评分信息（如\"Vera Institute of Justice\\n3.2\"）\n",
    "df_da['Company Name'] = df_da['Company Name'].str.extract(r'(.+?)(?:\\n(\\d+\\.\\d+))?$')[0]\n",
    "df_da.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst, Center on Immigration and Justic...</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>Are you eager to roll up your sleeves and harn...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Vera Institute of Justice</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>1961</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Social Assistance</td>\n",
       "      <td>Non-Profit</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quality Data Analyst</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>Overview\\n\\nProvides analytical and technical ...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Visiting Nurse Service of New York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1893</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Health Care Services &amp; Hospitals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>$2 to $5 billion (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst, Insights &amp; Analytics Team...</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>We__e looking for a Senior Data Analyst who ha...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Squarespace</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2003</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>GoDaddy</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>Requisition NumberRR-0001939\\nRemote:Yes\\nWe c...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Celerity</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>2002</td>\n",
       "      <td>Subsidiary or Business Segment</td>\n",
       "      <td>IT Services</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$50 to $100 million (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reporting Data Analyst</td>\n",
       "      <td>$37K-$66K (Glassdoor est.)</td>\n",
       "      <td>ABOUT FANDUEL GROUP\\n\\nFanDuel Group is a worl...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>FanDuel</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2009</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Sports &amp; Recreation</td>\n",
       "      <td>Arts, Entertainment &amp; Recreation</td>\n",
       "      <td>$100 to $500 million (USD)</td>\n",
       "      <td>DraftKings</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>RQS - IHHA - 201900004460 -1q Data Security An...</td>\n",
       "      <td>$78K-$104K (Glassdoor est.)</td>\n",
       "      <td>Maintains systems to protect data from unautho...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Avacend, Inc.</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>-1</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Staffing &amp; Outsourcing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>Senior Data Analyst (Corporate Audit)</td>\n",
       "      <td>$78K-$104K (Glassdoor est.)</td>\n",
       "      <td>Position:\\nSenior Data Analyst (Corporate Audi...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>Centennial, CO</td>\n",
       "      <td>Centennial, CO</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1935</td>\n",
       "      <td>Company - Public</td>\n",
       "      <td>Wholesale</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>$10+ billion (USD)</td>\n",
       "      <td>Avnet, Ingram Micro, Tech Data</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>Technical Business Analyst (SQL, Data analytic...</td>\n",
       "      <td>$78K-$104K (Glassdoor est.)</td>\n",
       "      <td>Title: Technical Business Analyst (SQL, Data a...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Spiceorb</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>Data Analyst 3, Customer Experience</td>\n",
       "      <td>$78K-$104K (Glassdoor est.)</td>\n",
       "      <td>Summary\\n\\nResponsible for working cross-funct...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Contingent Network Services</td>\n",
       "      <td>Centennial, CO</td>\n",
       "      <td>West Chester, OH</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>1984</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Enterprise Software &amp; Network Solutions</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$25 to $50 million (USD)</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>Senior Quality Data Analyst</td>\n",
       "      <td>$78K-$104K (Glassdoor est.)</td>\n",
       "      <td>You.\\n\\nYou bring your body, mind, heart and s...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>SCL Health</td>\n",
       "      <td>Broomfield, CO</td>\n",
       "      <td>Broomfield, CO</td>\n",
       "      <td>10000+ employees</td>\n",
       "      <td>1864</td>\n",
       "      <td>Nonprofit Organization</td>\n",
       "      <td>Health Care Services &amp; Hospitals</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>$2 to $5 billion (USD)</td>\n",
       "      <td>Centura Health, HealthONE, Denver Health and H...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2253 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Job Title  \\\n",
       "0     Data Analyst, Center on Immigration and Justic...   \n",
       "1                                  Quality Data Analyst   \n",
       "2     Senior Data Analyst, Insights & Analytics Team...   \n",
       "3                                          Data Analyst   \n",
       "4                                Reporting Data Analyst   \n",
       "...                                                 ...   \n",
       "2248  RQS - IHHA - 201900004460 -1q Data Security An...   \n",
       "2249              Senior Data Analyst (Corporate Audit)   \n",
       "2250  Technical Business Analyst (SQL, Data analytic...   \n",
       "2251                Data Analyst 3, Customer Experience   \n",
       "2252                        Senior Quality Data Analyst   \n",
       "\n",
       "                  Salary Estimate  \\\n",
       "0      $37K-$66K (Glassdoor est.)   \n",
       "1      $37K-$66K (Glassdoor est.)   \n",
       "2      $37K-$66K (Glassdoor est.)   \n",
       "3      $37K-$66K (Glassdoor est.)   \n",
       "4      $37K-$66K (Glassdoor est.)   \n",
       "...                           ...   \n",
       "2248  $78K-$104K (Glassdoor est.)   \n",
       "2249  $78K-$104K (Glassdoor est.)   \n",
       "2250  $78K-$104K (Glassdoor est.)   \n",
       "2251  $78K-$104K (Glassdoor est.)   \n",
       "2252  $78K-$104K (Glassdoor est.)   \n",
       "\n",
       "                                        Job Description  Rating  \\\n",
       "0     Are you eager to roll up your sleeves and harn...     3.2   \n",
       "1     Overview\\n\\nProvides analytical and technical ...     3.8   \n",
       "2     We__e looking for a Senior Data Analyst who ha...     3.4   \n",
       "3     Requisition NumberRR-0001939\\nRemote:Yes\\nWe c...     4.1   \n",
       "4     ABOUT FANDUEL GROUP\\n\\nFanDuel Group is a worl...     3.9   \n",
       "...                                                 ...     ...   \n",
       "2248  Maintains systems to protect data from unautho...     2.5   \n",
       "2249  Position:\\nSenior Data Analyst (Corporate Audi...     2.9   \n",
       "2250  Title: Technical Business Analyst (SQL, Data a...    -1.0   \n",
       "2251  Summary\\n\\nResponsible for working cross-funct...     3.1   \n",
       "2252  You.\\n\\nYou bring your body, mind, heart and s...     3.4   \n",
       "\n",
       "                            Company Name        Location      Headquarters  \\\n",
       "0              Vera Institute of Justice    New York, NY      New York, NY   \n",
       "1     Visiting Nurse Service of New York    New York, NY      New York, NY   \n",
       "2                            Squarespace    New York, NY      New York, NY   \n",
       "3                               Celerity    New York, NY        McLean, VA   \n",
       "4                                FanDuel    New York, NY      New York, NY   \n",
       "...                                  ...             ...               ...   \n",
       "2248                       Avacend, Inc.      Denver, CO    Alpharetta, GA   \n",
       "2249                   Arrow Electronics  Centennial, CO    Centennial, CO   \n",
       "2250                            Spiceorb      Denver, CO                -1   \n",
       "2251         Contingent Network Services  Centennial, CO  West Chester, OH   \n",
       "2252                          SCL Health  Broomfield, CO    Broomfield, CO   \n",
       "\n",
       "                        Size  Founded               Type of ownership  \\\n",
       "0       201 to 500 employees     1961          Nonprofit Organization   \n",
       "1           10000+ employees     1893          Nonprofit Organization   \n",
       "2     1001 to 5000 employees     2003               Company - Private   \n",
       "3       201 to 500 employees     2002  Subsidiary or Business Segment   \n",
       "4      501 to 1000 employees     2009               Company - Private   \n",
       "...                      ...      ...                             ...   \n",
       "2248     51 to 200 employees       -1               Company - Private   \n",
       "2249        10000+ employees     1935                Company - Public   \n",
       "2250                      -1       -1                              -1   \n",
       "2251    201 to 500 employees     1984               Company - Private   \n",
       "2252        10000+ employees     1864          Nonprofit Organization   \n",
       "\n",
       "                                     Industry  \\\n",
       "0                           Social Assistance   \n",
       "1            Health Care Services & Hospitals   \n",
       "2                                    Internet   \n",
       "3                                 IT Services   \n",
       "4                         Sports & Recreation   \n",
       "...                                       ...   \n",
       "2248                   Staffing & Outsourcing   \n",
       "2249                                Wholesale   \n",
       "2250                                       -1   \n",
       "2251  Enterprise Software & Network Solutions   \n",
       "2252         Health Care Services & Hospitals   \n",
       "\n",
       "                                Sector                     Revenue  \\\n",
       "0                           Non-Profit  $100 to $500 million (USD)   \n",
       "1                          Health Care      $2 to $5 billion (USD)   \n",
       "2               Information Technology    Unknown / Non-Applicable   \n",
       "3               Information Technology   $50 to $100 million (USD)   \n",
       "4     Arts, Entertainment & Recreation  $100 to $500 million (USD)   \n",
       "...                                ...                         ...   \n",
       "2248                 Business Services    Unknown / Non-Applicable   \n",
       "2249                 Business Services          $10+ billion (USD)   \n",
       "2250                                -1                          -1   \n",
       "2251            Information Technology    $25 to $50 million (USD)   \n",
       "2252                       Health Care      $2 to $5 billion (USD)   \n",
       "\n",
       "                                            Competitors Easy Apply  \n",
       "0                                                    -1       TRUE  \n",
       "1                                                    -1         -1  \n",
       "2                                               GoDaddy         -1  \n",
       "3                                                    -1         -1  \n",
       "4                                            DraftKings       TRUE  \n",
       "...                                                 ...        ...  \n",
       "2248                                                 -1         -1  \n",
       "2249                     Avnet, Ingram Micro, Tech Data         -1  \n",
       "2250                                                 -1         -1  \n",
       "2251                                                 -1         -1  \n",
       "2252  Centura Health, HealthONE, Denver Health and H...         -1  \n",
       "\n",
       "[2253 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 第四步：薪资标准化\n",
    "# =====================\n",
    "\n",
    "# 定义标准化薪资的函数\n",
    "def standardize_salary(s):\n",
    "    if isinstance(s, str):\n",
    "        # 检查是否只包含 '-1'\n",
    "        if s.strip() == '-1':\n",
    "            return [np.nan, np.nan, np.nan]  # 直接返回无效数据标记\n",
    "        \n",
    "        # 处理 df_da 格式: $37K-$66K (Glassdoor est.)\n",
    "        numbers = re.findall(r'\\$(\\d+)K', s)\n",
    "        if len(numbers) == 2:\n",
    "            try:\n",
    "                # 将提取的数字转换为整数，并计算平均值\n",
    "                numbers = [int(n) * 1000 for n in numbers]\n",
    "                avg = (numbers[0] + numbers[1]) / 2  # 使用浮点除法\n",
    "                return numbers + [avg]\n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing '{s}': {e}\")\n",
    "                return [np.nan, np.nan, np.nan]\n",
    "        \n",
    "        # 处理 df_ds 格式: 56-97\n",
    "        elif '-' in s:\n",
    "            numbers = s.split('-')\n",
    "            if len(numbers) == 2:\n",
    "                try:\n",
    "                    # 将提取的数字转换为整数，并计算平均值\n",
    "                    numbers = [int(n) * 1000 for n in numbers]\n",
    "                    avg = (numbers[0] + numbers[1]) / 2  # 使用浮点除法\n",
    "                    return numbers + [avg]\n",
    "                except ValueError:\n",
    "                    print(f\"Error processing '{s}': Invalid number format\")\n",
    "                    return [np.nan, np.nan, np.nan]\n",
    "            else:\n",
    "                print(f\"Invalid format for '{s}'\")\n",
    "                return [np.nan, np.nan, np.nan]\n",
    "        else:\n",
    "            print(f\"Invalid format for '{s}'\")\n",
    "            return [np.nan, np.nan, np.nan]\n",
    "    else:\n",
    "        print(f\"Invalid input type: {type(s)}\")\n",
    "        return [np.nan, np.nan, np.nan]\n",
    "# 应用标准化函数\n",
    "salary_data_ds = df_ds['Salary Estimate'].apply(standardize_salary).apply(pd.Series)\n",
    "salary_data_ds.columns = ['Salary_Min', 'Salary_Max', 'Salary_Avg']\n",
    "\n",
    "# 将处理后的数据合并到原始 DataFrame 中\n",
    "df_ds = pd.concat([df_ds, salary_data_ds], axis=1)\n",
    "# 删除原有数据\n",
    "df_ds.drop(columns=['Salary Estimate','min_salary', 'max_salary', 'avg_salary'], inplace=True)\n",
    "\n",
    "\n",
    "# 应用标准化函数\n",
    "salary_data_da = df_da['Salary Estimate'].apply(standardize_salary).apply(pd.Series)\n",
    "salary_data_da.columns = ['Salary_Min', 'Salary_Max', 'Salary_Avg']\n",
    "\n",
    "# 将处理后的数据合并到原始 DataFrame 中\n",
    "df_da = pd.concat([df_da, salary_data_da], axis=1)\n",
    "df_da.drop(columns=['Salary Estimate'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 第五步：地理位置标准化\n",
    "# =====================\n",
    "\n",
    "def parse_location(loc):\n",
    "    \"\"\"将\"New York, NY\"分解为城市和州\"\"\"\n",
    "    if pd.notna(loc):\n",
    "        parts = loc.split(', ')\n",
    "        if len(parts) == 2:\n",
    "            return parts[0], parts[1]\n",
    "    return np.nan, np.nan\n",
    "\n",
    "for df in [df_ds, df_da]:\n",
    "    df[['City', 'State']] = df['Location'].apply(parse_location).apply(pd.Series)\n",
    "    df.drop(columns=['Location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义统一的列结构\n",
    "unified_columns = [\n",
    "    # 工作基础信息\n",
    "    'Job Title', 'Job Description', 'City', 'State', 'job_state', 'same_state', 'job_simp', 'seniority', 'Easy Apply', 'Competitors',\n",
    "    # 公司信息\n",
    "    'Company Name', 'Headquarters', 'Size', 'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Founded', 'Rating',\n",
    "    # 技能信息\n",
    "    'python', 'excel', 'hadoop', 'spark', 'aws', 'tableau', 'big_data',\n",
    "    # 工资信息\n",
    "    'Salary_Min', 'Salary_Max', 'Salary_Avg'\n",
    "]\n",
    "\n",
    "# 获取两个数据集的列名\n",
    "columns_ds = set(df_ds.columns)\n",
    "columns_da = set(df_da.columns)\n",
    "\n",
    "# 找出 df_ds 中存在但 df_da 中不存在的列\n",
    "missing_in_da = columns_ds - columns_da\n",
    "\n",
    "# 找出 df_da 中存在但 df_ds 中不存在的列\n",
    "missing_in_ds = columns_da - columns_ds\n",
    "\n",
    "# =====================\n",
    "# 第三步：处理 df_da 特有列\n",
    "# =====================\n",
    "# 添加 df_ds 中缺失的列到 df_da，并填充默认值\n",
    "for col in missing_in_da:\n",
    "    df_da[col] = np.nan  # 标记为待后续处理\n",
    "\n",
    "# =====================\n",
    "# 第四步：处理 df_ds 特有列\n",
    "# =====================\n",
    "# 添加 df_da 中缺失的列到 df_ds，并填充默认值\n",
    "for col in missing_in_ds:\n",
    "    df_ds[col] = np.nan\n",
    "\n",
    "# =====================\n",
    "# 第五步：确保两个 DataFrame 的列顺序一致\n",
    "# =====================\n",
    "# 重新排列列顺序，确保两个 DataFrame 的列顺序一致\n",
    "df_ds = df_ds[unified_columns]\n",
    "df_da = df_da[unified_columns]\n",
    "\n",
    "# =====================\n",
    "# 第六步：最终合并\n",
    "# =====================\n",
    "# 合并数据集\n",
    "combined_df = pd.concat([df_ds, df_da], ignore_index=True)\n",
    "\n",
    "\n",
    "# 保存结果\n",
    "combined_df.to_csv('./outputs/combined_jobs_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>job_state</th>\n",
       "      <th>same_state</th>\n",
       "      <th>job_simp</th>\n",
       "      <th>seniority</th>\n",
       "      <th>Easy Apply</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>...</th>\n",
       "      <th>python</th>\n",
       "      <th>excel</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>tableau</th>\n",
       "      <th>big_data</th>\n",
       "      <th>Salary_Min</th>\n",
       "      <th>Salary_Max</th>\n",
       "      <th>Salary_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Description\\n\\nThe Senior Data Scientist is re...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>senior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>154000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Secure our Nation, Ignite your Future\\n\\nJoin ...</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>VA</td>\n",
       "      <td>VA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>154000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Overview\\n\\n\\nAnalysis Group is one of the lar...</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>MA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>154000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>JOB DESCRIPTION:\\n\\nDo you have a passion for ...</td>\n",
       "      <td>Newton</td>\n",
       "      <td>MA</td>\n",
       "      <td>MA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>154000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist\\nAffinity Solutions / Marketing...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>na</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137000.0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>154000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>RQS - IHHA - 201900004460 -1q Data Security An...</td>\n",
       "      <td>Maintains systems to protect data from unautho...</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>91000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>Senior Data Analyst (Corporate Audit)</td>\n",
       "      <td>Position:\\nSenior Data Analyst (Corporate Audi...</td>\n",
       "      <td>Centennial</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Avnet, Ingram Micro, Tech Data</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>91000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>Technical Business Analyst (SQL, Data analytic...</td>\n",
       "      <td>Title: Technical Business Analyst (SQL, Data a...</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>91000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>Data Analyst 3, Customer Experience</td>\n",
       "      <td>Summary\\n\\nResponsible for working cross-funct...</td>\n",
       "      <td>Centennial</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>91000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>Senior Quality Data Analyst</td>\n",
       "      <td>You.\\n\\nYou bring your body, mind, heart and s...</td>\n",
       "      <td>Broomfield</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>Centura Health, HealthONE, Denver Health and H...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>91000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2913 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Job Title  \\\n",
       "0                                     Sr Data Scientist   \n",
       "1                                        Data Scientist   \n",
       "2                                        Data Scientist   \n",
       "3                                        Data Scientist   \n",
       "4                                        Data Scientist   \n",
       "...                                                 ...   \n",
       "2908  RQS - IHHA - 201900004460 -1q Data Security An...   \n",
       "2909              Senior Data Analyst (Corporate Audit)   \n",
       "2910  Technical Business Analyst (SQL, Data analytic...   \n",
       "2911                Data Analyst 3, Customer Experience   \n",
       "2912                        Senior Quality Data Analyst   \n",
       "\n",
       "                                        Job Description        City State  \\\n",
       "0     Description\\n\\nThe Senior Data Scientist is re...    New York    NY   \n",
       "1     Secure our Nation, Ignite your Future\\n\\nJoin ...   Chantilly    VA   \n",
       "2     Overview\\n\\n\\nAnalysis Group is one of the lar...      Boston    MA   \n",
       "3     JOB DESCRIPTION:\\n\\nDo you have a passion for ...      Newton    MA   \n",
       "4     Data Scientist\\nAffinity Solutions / Marketing...    New York    NY   \n",
       "...                                                 ...         ...   ...   \n",
       "2908  Maintains systems to protect data from unautho...      Denver    CO   \n",
       "2909  Position:\\nSenior Data Analyst (Corporate Audi...  Centennial    CO   \n",
       "2910  Title: Technical Business Analyst (SQL, Data a...      Denver    CO   \n",
       "2911  Summary\\n\\nResponsible for working cross-funct...  Centennial    CO   \n",
       "2912  You.\\n\\nYou bring your body, mind, heart and s...  Broomfield    CO   \n",
       "\n",
       "     job_state  same_state        job_simp seniority Easy Apply  \\\n",
       "0           NY         1.0  data scientist    senior        NaN   \n",
       "1           VA         0.0  data scientist        na        NaN   \n",
       "2           MA         1.0  data scientist        na        NaN   \n",
       "3           MA         0.0  data scientist        na        NaN   \n",
       "4           NY         1.0  data scientist        na        NaN   \n",
       "...        ...         ...             ...       ...        ...   \n",
       "2908       NaN         NaN             NaN       NaN         -1   \n",
       "2909       NaN         NaN             NaN       NaN         -1   \n",
       "2910       NaN         NaN             NaN       NaN         -1   \n",
       "2911       NaN         NaN             NaN       NaN         -1   \n",
       "2912       NaN         NaN             NaN       NaN         -1   \n",
       "\n",
       "                                            Competitors  ... python excel  \\\n",
       "0                                                   NaN  ...    0.0   0.0   \n",
       "1                                                   NaN  ...    0.0   0.0   \n",
       "2                                                   NaN  ...    1.0   1.0   \n",
       "3                                                   NaN  ...    1.0   1.0   \n",
       "4                                                   NaN  ...    1.0   1.0   \n",
       "...                                                 ...  ...    ...   ...   \n",
       "2908                                                 -1  ...    NaN   NaN   \n",
       "2909                     Avnet, Ingram Micro, Tech Data  ...    NaN   NaN   \n",
       "2910                                                 -1  ...    NaN   NaN   \n",
       "2911                                                 -1  ...    NaN   NaN   \n",
       "2912  Centura Health, HealthONE, Denver Health and H...  ...    NaN   NaN   \n",
       "\n",
       "     hadoop spark  aws tableau big_data  Salary_Min  Salary_Max  Salary_Avg  \n",
       "0       0.0   0.0  1.0     0.0      0.0    137000.0    171000.0    154000.0  \n",
       "1       1.0   0.0  0.0     0.0      1.0    137000.0    171000.0    154000.0  \n",
       "2       0.0   0.0  1.0     0.0      0.0    137000.0    171000.0    154000.0  \n",
       "3       0.0   0.0  1.0     0.0      0.0    137000.0    171000.0    154000.0  \n",
       "4       0.0   0.0  0.0     0.0      0.0    137000.0    171000.0    154000.0  \n",
       "...     ...   ...  ...     ...      ...         ...         ...         ...  \n",
       "2908    NaN   NaN  NaN     NaN      NaN     78000.0    104000.0     91000.0  \n",
       "2909    NaN   NaN  NaN     NaN      NaN     78000.0    104000.0     91000.0  \n",
       "2910    NaN   NaN  NaN     NaN      NaN     78000.0    104000.0     91000.0  \n",
       "2911    NaN   NaN  NaN     NaN      NaN     78000.0    104000.0     91000.0  \n",
       "2912    NaN   NaN  NaN     NaN      NaN     78000.0    104000.0     91000.0  \n",
       "\n",
       "[2913 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
